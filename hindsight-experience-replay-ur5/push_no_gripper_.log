env.spec.id:  ur5_push_no_gripper-v1
args:  env.spec.id:  ur5_push_no_gripper-v1
args:  Namespace(action_l2=1, batch_size=256, buffer_size=1000000, clip_obs=200, clip_range=5, clip_return=50, cuda=False, demo_length=20, env_name='ur5_push_no_gripper-v1', gamma=0.98, lr_actor=0.001, lr_critic=0.001, n_batches=40, n_cycles=50, n_epochs=80, n_test_rollouts=10, noise_eps=0.2, num_rollouts_per_mpi=2, num_workers=1, polyak=0.95, random_eps=0.3, replay_k=4, replay_strategy='future', save_dir='saved_models/', save_interval=5, seed=123)
env_params Namespace(action_l2=1, batch_size=256, buffer_size=1000000, clip_obs=200, clip_range=5, clip_return=50, cuda=False, demo_length=20, env_name='ur5_push_no_gripper-v1', gamma=0.98, lr_actor=0.001, lr_critic=0.001, n_batches=40, n_cycles=50, n_epochs=80, n_test_rollouts=10, noise_eps=0.2, num_rollouts_per_mpi=2, num_workers=1, polyak=0.95, random_eps=0.3, replay_k=4, replay_strategy='future', save_dir='saved_models/', save_interval=5, seed=123)
env_params {'obs': 25, 'goal': 3, 'action': 4, 'action_max': 1.0, 'max_timesteps': 100}
CONTINUE TRAINING...
{'obs': 25, 'goal': 3, 'action': 4, 'action_max': 1.0, 'max_timesteps': 100}
CONTINUE TRAINING...
Traceback (most recent call last):
  File "train.py", line 55, in <module>
Traceback (most recent call last):
  File "train.py", line 55, in <module>
    launch(args)
  File "train.py", line 44, in launch
    launch(args)
  File "train.py", line 44, in launch
    ddpg_trainer = ddpg_agent(args, env, env_params)
  File "/home/stefan/Documents/Masterarbeit/DRL/hindsight-experience-replay-ur5/rl_modules/ddpg_agent.py", line 42, in __init__
    ddpg_trainer = ddpg_agent(args, env, env_params)
  File "/home/stefan/Documents/Masterarbeit/DRL/hindsight-experience-replay-ur5/rl_modules/ddpg_agent.py", line 42, in __init__
    saved_dicts = load_saved_state_dicts(args.save_dir, env_name)
      File "/home/stefan/Documents/Masterarbeit/DRL/hindsight-experience-replay-ur5/rl_modules/utils.py", line 16, in load_saved_state_dicts
saved_dicts = load_saved_state_dicts(args.save_dir, env_name)
  File "/home/stefan/Documents/Masterarbeit/DRL/hindsight-experience-replay-ur5/rl_modules/utils.py", line 16, in load_saved_state_dicts
    model_path, map_location=lambda storage, loc: storage),    model_path, map_location=lambda storage, loc: storage),
ValueError: not enough values to unpack (expected 8, got 1)

ValueError: not enough values to unpack (expected 8, got 1)
env.spec.id:  ur5_push_no_gripper-v1
args:  env.spec.id:  ur5_push_no_gripper-v1
args:  Namespace(action_l2=1, batch_size=256, buffer_size=1000000, clip_obs=200, clip_range=5, clip_return=50, cuda=False, demo_length=20, env_name='ur5_push_no_gripper-v1', gamma=0.98, lr_actor=0.001, lr_critic=0.001, n_batches=40, n_cycles=50, n_epochs=80, n_test_rollouts=10, noise_eps=0.2, num_rollouts_per_mpi=2, num_workers=1, polyak=0.95, random_eps=0.3, replay_k=4, replay_strategy='future', save_dir='saved_models/', save_interval=5, seed=123)
env_params {'obs': 25, 'goal': 3, 'action': 4, 'action_max': 1.0, 'max_timesteps': 100}Namespace(action_l2=1, batch_size=256, buffer_size=1000000, clip_obs=200, clip_range=5, clip_return=50, cuda=False, demo_length=20, env_name='ur5_push_no_gripper-v1', gamma=0.98, lr_actor=0.001, lr_critic=0.001, n_batches=40, n_cycles=50, n_epochs=80, n_test_rollouts=10, noise_eps=0.2, num_rollouts_per_mpi=2, num_workers=1, polyak=0.95, random_eps=0.3, replay_k=4, replay_strategy='future', save_dir='saved_models/', save_interval=5, seed=123)
env_params 
CONTINUE TRAINING...
{'obs': 25, 'goal': 3, 'action': 4, 'action_max': 1.0, 'max_timesteps': 100}
CONTINUE TRAINING...
Traceback (most recent call last):
  File "train.py", line 55, in <module>
    launch(args)
  File "train.py", line 44, in launch
    ddpg_trainer = ddpg_agent(args, env, env_params)
  File "/home/stefan/Documents/Masterarbeit/DRL/hindsight-experience-replay-ur5/rl_modules/ddpg_agent.py", line 42, in __init__
    saved_dicts = load_saved_state_dicts(args.save_dir, env_name)
  File "/home/stefan/Documents/Masterarbeit/DRL/hindsight-experience-replay-ur5/rl_modules/utils.py", line 16, in load_saved_state_dicts
    model_path, map_location=lambda storage, loc: storage),
ValueError: not enough values to unpack (expected 8, got 1)
Traceback (most recent call last):
  File "train.py", line 55, in <module>
    launch(args)
  File "train.py", line 44, in launch
    ddpg_trainer = ddpg_agent(args, env, env_params)
  File "/home/stefan/Documents/Masterarbeit/DRL/hindsight-experience-replay-ur5/rl_modules/ddpg_agent.py", line 42, in __init__
    saved_dicts = load_saved_state_dicts(args.save_dir, env_name)
  File "/home/stefan/Documents/Masterarbeit/DRL/hindsight-experience-replay-ur5/rl_modules/utils.py", line 16, in load_saved_state_dicts
    model_path, map_location=lambda storage, loc: storage),
ValueError: not enough values to unpack (expected 8, got 1)
