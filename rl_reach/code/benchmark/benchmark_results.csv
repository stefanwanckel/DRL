env_id,random_position,random_orientation,moving_target,target_type,goal_oriented,obs_type,reward_type,action_type,joint_limits,action_min,action_max,alpha_reward,reward_coeff,exp_id,algo,nb_seeds,nb_eval_timesteps,deterministic,goal_selection_strategy,max_episode_length,model_class,n_sampled_goal,n_timesteps,normalize,online_sampling,policy,nb_eval_ep_during_training,eval_freq_during_training,vec_env,num_threads,mean_train_time(s),std_train_time(s),min_train_time(s),simulated_time(s),mean_return,std_return,max_return,mean_SR_pos_50,std_SR_pos_50,max_SR_pos_50,mean_RT_pos_50,std_RT_pos_50,max_RT_pos_50,mean_SR_pos_20,std_SR_pos_20,max_SR_pos_20,mean_RT_pos_20,std_RT_pos_20,max_RT_pos_20,mean_SR_pos_10,std_SR_pos_10,max_SR_pos_10,mean_RT_pos_10,std_RT_pos_10,max_RT_pos_10,mean_SR_pos_5,std_SR_pos_5,max_SR_pos_5,mean_RT_pos_5,std_RT_pos_5,max_RT_pos_5,mean_SR_pos_2,std_SR_pos_2,max_SR_pos_2,mean_RT_pos_2,std_RT_pos_2,max_RT_pos_2,mean_SR_pos_1,std_SR_pos_1,max_SR_pos_1,mean_RT_pos_1,std_RT_pos_1,max_RT_pos_1,mean_SR_pos_05,std_SR_pos_05,max_SR_pos_05,mean_RT_pos_05,std_RT_pos_05,max_RT_pos_05,mean_SR_orient_50,std_SR_orient_50,max_SR_orient_50,mean_RT_orient_50,std_RT_orient_50,max_RT_orient_50,mean_SR_orient_20,std_SR_orient_20,max_SR_orient_20,mean_RT_orient_20,std_RT_orient_20,max_RT_orient_20,mean_SR_orient_10,std_SR_orient_10,max_SR_orient_10,mean_RT_orient_10,std_RT_orient_10,max_RT_orient_10,mean_SR_orient_5,std_SR_orient_5,max_SR_orient_5,mean_RT_orient_5,std_RT_orient_5,max_RT_orient_5,mean_SR_orient_2,std_SR_orient_2,max_SR_orient_2,mean_RT_orient_2,std_RT_orient_2,max_RT_orient_2,mean_SR_orient_1,std_SR_orient_1,max_SR_orient_1,mean_RT_orient_1,std_RT_orient_1,max_RT_orient_1,mean_SR_orient_05,std_SR_orient_05,max_SR_orient_05,mean_RT_orient_05,std_RT_orient_05,max_RT_orient_05
widowx_reacher-v3,False,False,False,sphere,False,3,1,1,large,"[-1, -1, -1, -1, -1, -1]","[1, 1, 1, 1, 1, 1]",0.1,1.0,3,her,1,300,1,future,300,td3,4,70000,True,True,MlpPolicy,1,10000,dummy,6,1849.3832049369807,,1849.3832049369807,291.6666666666667,-5.999999865889549,,-5.999999865889549,0.0,,0.0,,,,0.0,,0.0,,,,0.0,,0.0,,,,0.0,,0.0,,,,0.0,,0.0,,,,0.0,,0.0,,,,0.0,,0.0,,,,0.0,,0.0,,,,0.0,,0.0,,,,0.0,,0.0,,,,0.0,,0.0,,,,0.0,,0.0,,,,0.0,,0.0,,,,0.0,,0.0,,,
widowx_reacher-v3,False,False,False,sphere,False,3,1,1,large,"[-1, -1, -1, -1, -1, -1]","[1, 1, 1, 1, 1, 1]",0.1,1.0,4,her,1,300,1,future,300,td3,4,70000,True,True,MlpPolicy,1,10000,dummy,6,1891.084918022156,,1891.084918022156,291.6666666666667,-5.999999865889549,,-5.999999865889549,0.0,,0.0,,,,0.0,,0.0,,,,0.0,,0.0,,,,0.0,,0.0,,,,0.0,,0.0,,,,0.0,,0.0,,,,0.0,,0.0,,,,0.0,,0.0,,,,0.0,,0.0,,,,0.0,,0.0,,,,0.0,,0.0,,,,0.0,,0.0,,,,0.0,,0.0,,,,0.0,,0.0,,,
